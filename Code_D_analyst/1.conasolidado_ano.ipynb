{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926b1041-c407-4321-bb2e-93807f26ecf9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1. LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bdd8e698-ee7d-4fb2-b8f0-4d51646bfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re  # Importamos para manejar expresiones regulares\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789430bf-1d3e-4487-9b40-ffee93aaf279",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2. LOCAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e841950e-1c46-443d-b450-de0a941f5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables globales\n",
    "#Nombre del dataframe final\n",
    "nombre_merged = \"neg_all_2019\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f53f2-6394-48b1-924c-d3bfe37639cc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. READING OF FOLDER WITH DATA NEGADOS OR VALIDADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "87b9caee-5059-4079-9d07-02ba1cfcd495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes):  \"C:\\Users\\carlo\\OneDrive\\Documentos\\dataP\\MUNICIPIOS 2019\\2019\\NEG\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo NSEPS02504102019.NEG cargado como df_04102019\n",
      "Archivo NSEPS02505042019.NEG cargado como df_05042019\n",
      "Archivo NSEPS02505072019.NEG cargado como df_05072019\n",
      "Archivo NSEPS02506092019.NEG cargado como df_06092019\n",
      "Archivo NSEPS02507062019.NEG cargado como df_07062019\n",
      "Archivo NSEPS02508022019.NEG cargado como df_08022019\n",
      "Archivo NSEPS02508032019.NEG cargado como df_08032019\n",
      "Archivo NSEPS02508112019.NEG cargado como df_08112019\n",
      "Archivo NSEPS02509082019.NEG cargado como df_09082019\n",
      "Archivo NSEPS02510052019.NEG cargado como df_10052019\n",
      "Archivo NSEPS02511012019.NEG cargado como df_11012019\n",
      "Archivo NSEPS02511102019.NEG cargado como df_11102019\n",
      "Archivo NSEPS02512042019.NEG cargado como df_12042019\n",
      "Archivo NSEPS02512072019.NEG cargado como df_12072019\n",
      "Archivo NSEPS02513092019.NEG cargado como df_13092019\n",
      "Archivo NSEPS02513122019.NEG cargado como df_13122019\n",
      "Archivo NSEPS02514062019.NEG cargado como df_14062019\n",
      "Archivo NSEPS02515022019.NEG cargado como df_15022019\n",
      "Archivo NSEPS02515032019.NEG cargado como df_15032019\n",
      "Archivo NSEPS02515112019.NEG cargado como df_15112019\n",
      "Archivo NSEPS02516082019.NEG cargado como df_16082019\n",
      "Archivo NSEPS02517052019.NEG cargado como df_17052019\n",
      "Archivo NSEPS02518012019.NEG cargado como df_18012019\n",
      "Archivo NSEPS02518102019.NEG cargado como df_18102019\n",
      "Archivo NSEPS02519072019.NEG cargado como df_19072019\n",
      "Archivo NSEPS02520092019.NEG cargado como df_20092019\n",
      "Archivo NSEPS02520122019.NEG cargado como df_20122019\n",
      "Archivo NSEPS02521062019.NEG cargado como df_21062019\n",
      "Archivo NSEPS02522022019.NEG cargado como df_22022019\n",
      "Archivo NSEPS02522032019.NEG cargado como df_22032019\n",
      "Archivo NSEPS02522112019.NEG cargado como df_22112019\n",
      "Archivo NSEPS02523082019.NEG cargado como df_23082019\n",
      "Archivo NSEPS02524052019.NEG cargado como df_24052019\n",
      "Archivo NSEPS02525012019.NEG cargado como df_25012019\n",
      "Archivo NSEPS02525102019.NEG cargado como df_25102019\n",
      "\n",
      "Se crearon 35 DataFrames en total.\n",
      "Se agregó la columna 'nombre_dataframe' a todos los DataFrames.\n",
      "Primeras filas de df_04102019:\n",
      "   col_1   col_2 col_3        col_4       col_5        col_6     col_7  \\\n",
      "0     16  EPS025    TI   1006413607   RODRIGUEZ    CASTAÑEDA      NANI   \n",
      "1     86  EPS025    TI   1006559623  CHAMARRAVI  GUACARAPARE   KINNEDY   \n",
      "2    133  EPS025    TI   1010107558       RIVAS      ALVAREZ       YAN   \n",
      "3    422  EPS025    TI  90010379279     MARQUEZ    HERNANDEZ  PATRICIA   \n",
      "4    477  EPS025    TI   1006450537       JAZPE      BARRETO     JULIO   \n",
      "\n",
      "      col_8       col_9  col_10  ...      col_13 col_14      col_15  \\\n",
      "0   MAYERLI  10/07/2001      85  ...  30/09/2019     CC  1006413607   \n",
      "1  BERNARDO  30/05/2000      85  ...  30/09/2019     CC  1006559623   \n",
      "2    CARLOS  26/11/2000      85  ...  30/09/2019     CC  1010107558   \n",
      "3       NaN  03/01/1990      85  ...  30/09/2019     CC  1118542994   \n",
      "4    DANIEL  07/06/2000      85  ...  30/09/2019     CC  1006450537   \n",
      "\n",
      "       col_16 col_17 col_18  col_19  col_20  \\\n",
      "0  10/07/2001    0.0    NaN     NaN     NaN   \n",
      "1  30/05/2000    0.0    NaN     NaN     NaN   \n",
      "2  26/11/2000    0.0    NaN     NaN     NaN   \n",
      "3  03/01/1990    0.0    NaN     NaN     NaN   \n",
      "4  07/06/2000    0.0    NaN     NaN     NaN   \n",
      "\n",
      "                                              col_21  nombre_dataframe  \n",
      "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...       df_04102019  \n",
      "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...       df_04102019  \n",
      "2  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...       df_04102019  \n",
      "3              GN0018(CC|1118542994|CANCELADO RNEC);       df_04102019  \n",
      "4  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...       df_04102019  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def obtener_ruta_carpeta():\n",
    "    folder_path = input('Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes): ')\n",
    "    folder_path = folder_path.strip('\"').replace(\"\\\\\", \"/\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no existe.\")\n",
    "        return None\n",
    "    return folder_path\n",
    "\n",
    "def cargar_archivos_a_dataframe(folder_path, extensiones=[\".NEG\", \".VAL\"], sep=\",\", encoding=\"latin-1\"):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no es válida.\")\n",
    "        return {}\n",
    "    \n",
    "    dataframes = {}\n",
    "    for ext in extensiones:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(ext):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, sep=sep, encoding=encoding, header=None)\n",
    "                    df.columns = [f\"col_{j+1}\" for j in range(df.shape[1])]\n",
    "                    \n",
    "                    nombre_base = os.path.splitext(filename)[0]  # Nombre sin extensión\n",
    "                    nombre_base = nombre_base.replace(\"NSEPS025\", \"\")  # Eliminar \"NSEPS025\" del nombre\n",
    "                    clave = f\"df_{nombre_base}\"  # Clave personalizada\n",
    "                    dataframes[clave] = df\n",
    "                    print(f\"Archivo {filename} cargado como {clave}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo leer el archivo {filename}: {e}\")\n",
    "    \n",
    "    total_df = len(dataframes)\n",
    "    print(f\"\\nSe crearon {total_df} DataFrames en total.\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(\"No se cargaron archivos en la carpeta especificada.\")\n",
    "    return dataframes\n",
    "\n",
    "def agregar_nombre_a_dataframes(dataframes):\n",
    "    \"\"\"\n",
    "    Agrega una columna adicional a cada DataFrame con su nombre (clave del diccionario).\n",
    "    \"\"\"\n",
    "    for name, df in dataframes.items():\n",
    "        df[\"nombre_dataframe\"] = name  # Agrega una columna con el nombre del DataFrame\n",
    "    print(\"Se agregó la columna 'nombre_dataframe' a todos los DataFrames.\")\n",
    "\n",
    "def mostrar_primeras_filas(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Primeras filas de {name}:\")\n",
    "        print(df.head())\n",
    "        print(\"\\n---\\n\")\n",
    "        # Puedes quitar el \"break\" si deseas mostrar todos los DataFrames\n",
    "        break\n",
    "\n",
    "# Ejecución del script\n",
    "ruta = obtener_ruta_carpeta()\n",
    "if ruta:\n",
    "    # Incluye las extensiones .NEG y .VAL\n",
    "    dataframes = cargar_archivos_a_dataframe(ruta, extensiones=[\".NEG\", \".VAL\"])\n",
    "    if dataframes:\n",
    "        # Agregar el nombre del DataFrame como columna\n",
    "        agregar_nombre_a_dataframes(dataframes)\n",
    "        # Mostrar las primeras filas de los DataFrames\n",
    "        mostrar_primeras_filas(dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04365f-26ba-47a8-8a5b-90321f60776d",
   "metadata": {},
   "source": [
    "Revisando las dimenciones de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3316c4b7-eafc-4652-84ca-908418d3b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si df_1 está en el diccionario 'dataframes', lo puedes acceder así:\n",
    "\n",
    "#dataframes['df_22112019'].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11893e78-333d-459e-9b4a-c57ebdfe436d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3.1 Searching the shape of all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "87efeeba-f798-4846-8235-49d1907d6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  Row  Cols\n",
      "df_04102019: 289  22\n",
      "df_05042019: 345  22\n",
      "df_05072019: 267  22\n",
      "df_06092019: 793  22\n",
      "df_07062019: 234  22\n",
      "df_08022019: 242  22\n",
      "df_08032019: 703  22\n",
      "df_08112019: 555  22\n",
      "df_09082019: 2105  22\n",
      "df_10052019: 402  22\n",
      "df_11012019: 227  22\n",
      "df_11102019: 359  22\n",
      "df_12042019: 437  22\n",
      "df_12072019: 225  22\n",
      "df_13092019: 194  22\n",
      "df_13122019: 227  22\n",
      "df_14062019: 219  22\n",
      "df_15022019: 394  22\n",
      "df_15032019: 491  22\n",
      "df_15112019: 553  22\n",
      "df_16082019: 229  22\n",
      "df_17052019: 483  22\n",
      "df_18012019: 264  22\n",
      "df_18102019: 413  22\n",
      "df_19072019: 229  22\n",
      "df_20092019: 199  22\n",
      "df_20122019: 199  22\n",
      "df_21062019: 205  22\n",
      "df_22022019: 402  22\n",
      "df_22032019: 298  22\n",
      "df_22112019: 305  22\n",
      "df_23082019: 168  22\n",
      "df_24052019: 214  22\n",
      "df_25012019: 235  22\n",
      "df_25102019: 273  22\n",
      "\n",
      "Total de registros en todos los DataFrames: 13377\n"
     ]
    }
   ],
   "source": [
    "print('Name  Row  Cols')\n",
    "\n",
    "# Lista para almacenar la cantidad de filas\n",
    "row_counts = []\n",
    "\n",
    "# Recorremos los DataFrames en el diccionario\n",
    "for name, df in dataframes.items():\n",
    "    rows, cols = df.shape\n",
    "    row_counts.append(rows)  # Añadimos la cantidad de filas a la lista\n",
    "    print(f\"{name}: {rows}  {cols}\")\n",
    "\n",
    "# Calculamos el total de filas\n",
    "total_rows = sum(row_counts)\n",
    "print(f\"\\nTotal de registros en todos los DataFrames: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013fb86-38f3-485b-864f-0e7b961b4000",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Creating the original Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "182a1b4f-d774-419c-b88b-4fd0d9ba899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame 'neg_all_2019': (13377, 22)\n",
      "Primeras 5 filas del DataFrame 'neg_all_2019':\n",
      "   col_1   col_2 col_3        col_4       col_5        col_6     col_7  \\\n",
      "0     16  EPS025    TI   1006413607   RODRIGUEZ    CASTAÑEDA      NANI   \n",
      "1     86  EPS025    TI   1006559623  CHAMARRAVI  GUACARAPARE   KINNEDY   \n",
      "2    133  EPS025    TI   1010107558       RIVAS      ALVAREZ       YAN   \n",
      "3    422  EPS025    TI  90010379279     MARQUEZ    HERNANDEZ  PATRICIA   \n",
      "4    477  EPS025    TI   1006450537       JAZPE      BARRETO     JULIO   \n",
      "\n",
      "      col_8       col_9  col_10  ...      col_13 col_14      col_15  \\\n",
      "0   MAYERLI  10/07/2001      85  ...  30/09/2019     CC  1006413607   \n",
      "1  BERNARDO  30/05/2000      85  ...  30/09/2019     CC  1006559623   \n",
      "2    CARLOS  26/11/2000      85  ...  30/09/2019     CC  1010107558   \n",
      "3       NaN  03/01/1990      85  ...  30/09/2019     CC  1118542994   \n",
      "4    DANIEL  07/06/2000      85  ...  30/09/2019     CC  1006450537   \n",
      "\n",
      "       col_16 col_17 col_18  col_19  col_20  \\\n",
      "0  10/07/2001    0.0    NaN     NaN     NaN   \n",
      "1  30/05/2000    0.0    NaN     NaN     NaN   \n",
      "2  26/11/2000    0.0    NaN     NaN     NaN   \n",
      "3  03/01/1990    0.0    NaN     NaN     NaN   \n",
      "4  07/06/2000    0.0    NaN     NaN     NaN   \n",
      "\n",
      "                                              col_21  nombre_dataframe  \n",
      "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...       df_04102019  \n",
      "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...       df_04102019  \n",
      "2  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...       df_04102019  \n",
      "3              GN0018(CC|1118542994|CANCELADO RNEC);       df_04102019  \n",
      "4  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...       df_04102019  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir el número de columnas deseadas\n",
    "num_columnas = 22\n",
    "\n",
    "# Asegurar que todos los DataFrames tengan exactamente el mismo número de columnas\n",
    "dataframes_alineados = {name: df.iloc[:, :num_columnas] for name, df in dataframes.items()}\n",
    "\n",
    "# Definir un nombre fijo para el DataFrame combinado\n",
    "#nombre_merged = \"merged_meses\"\n",
    "\n",
    "# Combinar todos los DataFrames alineados, sin crear nuevas columnas\n",
    "globals()[nombre_merged] = pd.concat(dataframes_alineados.values(), axis=0, ignore_index=True)\n",
    "\n",
    "# Mostrar el shape del DataFrame combinado\n",
    "print(f\"Shape del DataFrame '{nombre_merged}': {globals()[nombre_merged].shape}\")\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(f\"Primeras 5 filas del DataFrame '{nombre_merged}':\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaf42e-1204-464f-a42c-c5257d3ad18a",
   "metadata": {},
   "source": [
    "## 4.1 Cheking the Merged's Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c5952f74-cd8f-40cf-98fc-4bc809e40306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',\n",
      "       'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15',\n",
      "       'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21',\n",
      "       'nombre_dataframe'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(globals()[nombre_merged].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6fc19-f11f-4ce4-8726-7991c0f41ef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2 Cleaning the Merged's colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3b1dd52a-c6b5-49ac-9229-bb9421ddc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col_2 col_3        col_4       col_9  col_10  col_11 col_12      col_13  \\\n",
      "0  EPS025    TI   1006413607  10/07/2001      85       1    N01  30/09/2019   \n",
      "1  EPS025    TI   1006559623  30/05/2000      85     125    N01  30/09/2019   \n",
      "2  EPS025    TI   1010107558  26/11/2000      85       1    N01  30/09/2019   \n",
      "3  EPS025    TI  90010379279  03/01/1990      85       1    N01  30/09/2019   \n",
      "4  EPS025    TI   1006450537  07/06/2000      85     430    N01  30/09/2019   \n",
      "\n",
      "  nombre_dataframe                                             col_21  \n",
      "0      df_04102019  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1      df_04102019  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2      df_04102019  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3      df_04102019              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4      df_04102019  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n"
     ]
    }
   ],
   "source": [
    "# Selecciona las columnas que deseas mantener\n",
    "globals()[nombre_merged] = globals()[nombre_merged][['col_2', 'col_3','col_4','col_9', 'col_10', 'col_11', 'col_12', 'col_13','nombre_dataframe','col_21']]\n",
    "#union_2019 = union_2019[['col_2', 'col_3','col_8','col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_21']]\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b40c1-e761-4f60-83f1-e755d8f825c7",
   "metadata": {},
   "source": [
    "## 4.3 Renaming colum names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1ddbfc2c-f526-4d60-b771-0d686f55bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colum1 colum2       colum3      colum4  colum5  colum6 colum7      colum8  \\\n",
      "0  EPS025     TI   1006413607  10/07/2001      85       1    N01  30/09/2019   \n",
      "1  EPS025     TI   1006559623  30/05/2000      85     125    N01  30/09/2019   \n",
      "2  EPS025     TI   1010107558  26/11/2000      85       1    N01  30/09/2019   \n",
      "3  EPS025     TI  90010379279  03/01/1990      85       1    N01  30/09/2019   \n",
      "4  EPS025     TI   1006450537  07/06/2000      85     430    N01  30/09/2019   \n",
      "\n",
      "        colum9                                            colum10  \n",
      "0  df_04102019  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1  df_04102019  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2  df_04102019  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3  df_04102019              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4  df_04102019  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n"
     ]
    }
   ],
   "source": [
    "# Obtiene la cantidad de columnas en el DataFrame\n",
    "num_columns = globals()[nombre_merged].shape[1]\n",
    "\n",
    "# Genera nuevos nombres de columnas: 'colum1', 'colum2', ..., 'columnN'\n",
    "new_columns = [f'colum{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Asigna los nuevos nombres de columnas al DataFrame\n",
    "globals()[nombre_merged].columns = new_columns\n",
    "\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "94ad6470-ddf6-4886-bae2-8418b42e837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colum1     object\n",
       "colum2     object\n",
       "colum3     object\n",
       "colum4     object\n",
       "colum5      int64\n",
       "colum6      int64\n",
       "colum7     object\n",
       "colum8     object\n",
       "colum9     object\n",
       "colum10    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef8d7b-afae-4b65-8cd8-035da21b5c5a",
   "metadata": {},
   "source": [
    "## 4.4 Looking for the column with df_ and converting to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c9b562d8-46b0-40e7-90a2-8700fe16436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformación realizada directamente en el DataFrame: neg_all_2019\n",
      "   colum1 colum2       colum3      colum4 colum5 colum6 colum7      colum8  \\\n",
      "0  EPS025     TI   1006413607  10/07/2001     85      1    N01  30/09/2019   \n",
      "1  EPS025     TI   1006559623  30/05/2000     85    125    N01  30/09/2019   \n",
      "2  EPS025     TI   1010107558  26/11/2000     85      1    N01  30/09/2019   \n",
      "3  EPS025     TI  90010379279  03/01/1990     85      1    N01  30/09/2019   \n",
      "4  EPS025     TI   1006450537  07/06/2000     85    430    N01  30/09/2019   \n",
      "\n",
      "       colum9                                            colum10  \n",
      "0  04/10/2019  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1  04/10/2019  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2  04/10/2019  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3  04/10/2019              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4  04/10/2019  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n"
     ]
    }
   ],
   "source": [
    "#import re  # Importamos para manejar expresiones regulares\n",
    "\n",
    "# Procesamos directamente el DataFrame en globals()\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    # Modificamos las celdas de cada columna según el patrón\n",
    "    globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(str).apply(\n",
    "        lambda x: re.sub(r'^df_(\\d{2})(\\d{2})(\\d{4})$', r'\\1/\\2/\\3', x) \n",
    "        if 'df_' in x else x\n",
    "    )\n",
    "\n",
    "# Confirmamos que la transformación se realizó\n",
    "print(f\"Transformación realizada directamente en el DataFrame: {nombre_merged}\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d1ce1-badb-4811-8431-ec8786257490",
   "metadata": {},
   "source": [
    "## 4.5 Change type of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8746a305-3ada-4c4e-b954-0db5496437e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión de tipos completada en el DataFrame: neg_all_2019\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Recorremos cada columna del DataFrame\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    # Convertir a entero si todos los valores son numéricos\n",
    "    if globals()[nombre_merged][column].apply(lambda x: str(x).isdigit()).all():\n",
    "        globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(int)\n",
    "    \n",
    "    # Convertir a datetime si los valores están en formato dd/mm/aaaa\n",
    "    else:\n",
    "        try:\n",
    "            globals()[nombre_merged][column] = pd.to_datetime(\n",
    "                globals()[nombre_merged][column], format='%d/%m/%Y', errors='raise'\n",
    "            )\n",
    "        except:\n",
    "            pass  # Si no es fecha, se deja igual\n",
    "\n",
    "print(f\"Conversión de tipos completada en el DataFrame: {nombre_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b85fec53-f18e-4894-96ef-2d02717155cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colum1             object\n",
       "colum2             object\n",
       "colum3             object\n",
       "colum4     datetime64[ns]\n",
       "colum5              int32\n",
       "colum6              int32\n",
       "colum7             object\n",
       "colum8     datetime64[ns]\n",
       "colum9     datetime64[ns]\n",
       "colum10            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "fd72d069-04ec-46b8-adf0-e5f15c94c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colum1</th>\n",
       "      <th>colum2</th>\n",
       "      <th>colum3</th>\n",
       "      <th>colum4</th>\n",
       "      <th>colum5</th>\n",
       "      <th>colum6</th>\n",
       "      <th>colum7</th>\n",
       "      <th>colum8</th>\n",
       "      <th>colum9</th>\n",
       "      <th>colum10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006413607</td>\n",
       "      <td>2001-07-10</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>N01</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006559623</td>\n",
       "      <td>2000-05-30</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>N01</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colum1 colum2      colum3     colum4  colum5  colum6 colum7     colum8  \\\n",
       "0  EPS025     TI  1006413607 2001-07-10      85       1    N01 2019-09-30   \n",
       "1  EPS025     TI  1006559623 2000-05-30      85     125    N01 2019-09-30   \n",
       "\n",
       "      colum9                                            colum10  \n",
       "0 2019-10-04  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
       "1 2019-10-04  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf3c7e-67aa-4e11-802a-1a9779cf8adc",
   "metadata": {},
   "source": [
    "## 4.6 Renaming names Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8795dbe8-6c4e-4627-a900-43287c8605c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas\n",
    "globals()[nombre_merged].columns = ['cod_reg', 'tip_doc', 'doc', 'fech_nac', 'dep', 'mun', 'nov', 'fech_1', 'fecha_rep', 'observs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f2383ada-31cc-4975-b319-4cf7f718518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13377, 10)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "83a6cf72-9bd0-4b3a-96e3-63f76391bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_reg</th>\n",
       "      <th>tip_doc</th>\n",
       "      <th>doc</th>\n",
       "      <th>fech_nac</th>\n",
       "      <th>dep</th>\n",
       "      <th>mun</th>\n",
       "      <th>nov</th>\n",
       "      <th>fech_1</th>\n",
       "      <th>fecha_rep</th>\n",
       "      <th>observs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006413607</td>\n",
       "      <td>2001-07-10</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>N01</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006559623</td>\n",
       "      <td>2000-05-30</td>\n",
       "      <td>85</td>\n",
       "      <td>125</td>\n",
       "      <td>N01</td>\n",
       "      <td>2019-09-30</td>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cod_reg tip_doc         doc   fech_nac  dep  mun  nov     fech_1  fecha_rep  \\\n",
       "0  EPS025      TI  1006413607 2001-07-10   85    1  N01 2019-09-30 2019-10-04   \n",
       "1  EPS025      TI  1006559623 2000-05-30   85  125  N01 2019-09-30 2019-10-04   \n",
       "\n",
       "                                             observs  \n",
       "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
       "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "2d17aa91-44bf-477d-bd43-af92afefaa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cod_reg              object\n",
       "tip_doc              object\n",
       "doc                  object\n",
       "fech_nac     datetime64[ns]\n",
       "dep                   int32\n",
       "mun                   int32\n",
       "nov                  object\n",
       "fech_1       datetime64[ns]\n",
       "fecha_rep    datetime64[ns]\n",
       "observs              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704203b-8cb3-4e00-aa3e-6e22a3990708",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5. DOWNLADING FENITIVE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "40f20b50-cb2a-44fb-a1b7-a8f98a2bc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo se ha guardado correctamente en: C:\\Users\\carlo\\Downloads\\neg_all_2019.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta donde se guardará el archivo Excel basado en la variable nombre_merged\n",
    "output_name = f\"{nombre_merged}.xlsx\"\n",
    "output_path = os.path.join(r\"C:\\Users\\carlo\\Downloads\", output_name)\n",
    "\n",
    "# Guardar el DataFrame como un archivo Excel\n",
    "globals()[nombre_merged].to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo se ha guardado correctamente en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba6f36-1e61-45ba-91f1-11fba321c5fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Notes\n",
    "\n",
    "Colega hasta aqui se exporta un archivo en formato xlx, esta pendiente que sumerced agregue el paso de tratamiento para la columna de observaciones, la idea seria que lo numere y lo agregue aqui. por otra parte si quiere optimizar este codigo es libre de hacerlo, estoy abierto a cualquier sugerencia para mejorar. Gracias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
