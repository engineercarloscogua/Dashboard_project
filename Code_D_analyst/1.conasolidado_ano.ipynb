{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926b1041-c407-4321-bb2e-93807f26ecf9",
   "metadata": {},
   "source": [
    "# 1. LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bdd8e698-ee7d-4fb2-b8f0-4d51646bfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re  # Importamos para manejar expresiones regulares\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789430bf-1d3e-4487-9b40-ffee93aaf279",
   "metadata": {},
   "source": [
    "# 2. LOCAL VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e841950e-1c46-443d-b450-de0a941f5fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables globales\n",
    "#Nombre del dataframe final\n",
    "nombre_merged = \"neg_all_2024\"\n",
    "# Definir la ruta donde se guardará el archivo Excel basado en la variable nombre_merged\n",
    "output_name = f\"{nombre_merged}.xlsx\"\n",
    "#output_path = os.path.join(r\"C:/Users/crist/OneDrive - Corporación Universitaria Remington UNIREMINGTON/Estudio/Ciencia de datos/Lumethik/eps-data-solutions/data/processed/\", output_name)\n",
    "output_path = os.path.join(r\"C:\\Users\\carlo\\Downloads\", output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "504f53f2-6394-48b1-924c-d3bfe37639cc",
   "metadata": {},
   "source": [
    "# 3. READING OF FOLDER WITH DATA NEGADOS OR VALIDADOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "87b9caee-5059-4079-9d07-02ba1cfcd495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes):  \"C:\\Users\\carlo\\OneDrive\\Documentos\\dataP\\2023\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo NSEPS02504082023.NEG cargado como df_04082023\n",
      "Archivo NSEPS02505052023.NEG cargado como df_05052023\n",
      "Archivo NSEPS02506012023.NEG cargado como df_06012023\n",
      "Archivo NSEPS02506102023.NEG cargado como df_06102023\n",
      "Archivo NSEPS02507072023.NEG cargado como df_07072023\n",
      "Archivo NSEPS02507122023.NEG cargado como df_07122023\n",
      "Archivo NSEPS02509062023.NEG cargado como df_09062023\n",
      "Archivo NSEPS02510022023.NEG cargado como df_10022023\n",
      "Archivo NSEPS02510032023.NEG cargado como df_10032023\n",
      "Archivo NSEPS02510112023.NEG cargado como df_10112023\n",
      "Archivo NSEPS02511082023.NEG cargado como df_11082023\n",
      "Archivo NSEPS02512052023.NEG cargado como df_12052023\n",
      "Archivo NSEPS02513012023.NEG cargado como df_13012023\n",
      "Archivo NSEPS02513102023.NEG cargado como df_13102023\n",
      "Archivo NSEPS02514042023.NEG cargado como df_14042023\n",
      "Archivo NSEPS02514072023.NEG cargado como df_14072023\n",
      "Archivo NSEPS02515092023.NEG cargado como df_15092023\n",
      "Archivo NSEPS02515122023.NEG cargado como df_15122023\n",
      "Archivo NSEPS02516062023.NEG cargado como df_16062023\n",
      "Archivo NSEPS02517022023.NEG cargado como df_17022023\n",
      "Archivo NSEPS02517032023.NEG cargado como df_17032023\n",
      "Archivo NSEPS02517112023.NEG cargado como df_17112023\n",
      "Archivo NSEPS02518082023.NEG cargado como df_18082023\n",
      "Archivo NSEPS02519052023.NEG cargado como df_19052023\n",
      "Archivo NSEPS02520012023.NEG cargado como df_20012023\n",
      "Archivo NSEPS02520102023.NEG cargado como df_20102023\n",
      "Archivo NSEPS02521042023.NEG cargado como df_21042023\n",
      "Archivo NSEPS02521072023.NEG cargado como df_21072023\n",
      "Archivo NSEPS02522092023.NEG cargado como df_22092023\n",
      "Archivo NSEPS02522122023.NEG cargado como df_22122023\n",
      "Archivo NSEPS02523062023.NEG cargado como df_23062023\n",
      "Archivo NSEPS02524032023.NEG cargado como df_24032023\n",
      "Archivo NSEPS02524112023.NEG cargado como df_24112023\n",
      "Archivo NSEPS02525082023.NEG cargado como df_25082023\n",
      "\n",
      "Se crearon 34 DataFrames en total.\n",
      "Se agregó la columna 'nombre_dataframe' a todos los DataFrames.\n",
      "Primeras filas de df_04082023:\n",
      "   col_1   col_2 col_3           col_4        col_5        col_6    col_7  \\\n",
      "0      2  EPS025    TI      1006450972       MONTES         DIAZ    LUZIO   \n",
      "1      6  EPS025    RC      1115916352      PONGUTA  BALLESTEROS      ZOE   \n",
      "2     10  EPS025    TI      1116662294     MANTILLA    GUTIERREZ   DANIEL   \n",
      "3     11  EPS025    TI      1117322442        AMARO    RODRIGUEZ    PEDRO   \n",
      "4     14  EPS025    CN  23071210557566  MENDIVELSON          PAN  HIJO DE   \n",
      "\n",
      "      col_8       col_9  col_10  ...      col_13 col_14      col_15  \\\n",
      "0    FABIAN  10/03/2001      85  ...  01/06/2023     CC  1006450972   \n",
      "1     MAHIA  23/07/2021      85  ...  21/07/2023     RC  1006405282   \n",
      "2       NaN  14/04/2003      85  ...  01/06/2023     CC  1116662294   \n",
      "3  SANTIAGO  15/02/2005      85  ...  01/05/2023     CC  1117322442   \n",
      "4       NaN  14/07/2023      85  ...  24/07/2023     RC  1222144572   \n",
      "\n",
      "       col_16 col_17 col_18 col_19  col_20  \\\n",
      "0  10/03/2001      0    NaN    NaN     NaN   \n",
      "1  23/07/2021      1    NaN    NaN     NaN   \n",
      "2  14/04/2003      0    NaN    NaN     NaN   \n",
      "3  15/02/2005      0    NaN    NaN     NaN   \n",
      "4  14/07/2023      0    NaN    NaN     NaN   \n",
      "\n",
      "                                              col_21  nombre_dataframe  \n",
      "0                                    GN0169(||||||);       df_04082023  \n",
      "1  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...       df_04082023  \n",
      "2                                    GN0169(||||||);       df_04082023  \n",
      "3  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...       df_04082023  \n",
      "4  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...       df_04082023  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def obtener_ruta_carpeta():\n",
    "    folder_path = input('Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes): ')\n",
    "    folder_path = folder_path.strip('\"').replace(\"\\\\\", \"/\")\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no existe.\")\n",
    "        return None\n",
    "    return folder_path\n",
    "\n",
    "def cargar_archivos_a_dataframe(folder_path, extensiones=[\".NEG\", \".VAL\"], sep=\",\", encoding=\"latin-1\"):\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"La ruta {folder_path} no es válida.\")\n",
    "        return {}\n",
    "    \n",
    "    dataframes = {}\n",
    "    for ext in extensiones:\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.endswith(ext):\n",
    "                file_path = os.path.join(folder_path, filename)\n",
    "                try:\n",
    "                    df = pd.read_csv(file_path, sep=sep, encoding=encoding, header=None)\n",
    "                    df.columns = [f\"col_{j+1}\" for j in range(df.shape[1])]\n",
    "                    \n",
    "                    nombre_base = os.path.splitext(filename)[0]  # Nombre sin extensión\n",
    "                    nombre_base = nombre_base.replace(\"NSEPS025\", \"\")  # Eliminar \"NSEPS025\" del nombre\n",
    "                    clave = f\"df_{nombre_base}\"  # Clave personalizada\n",
    "                    dataframes[clave] = df\n",
    "                    print(f\"Archivo {filename} cargado como {clave}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"No se pudo leer el archivo {filename}: {e}\")\n",
    "    \n",
    "    total_df = len(dataframes)\n",
    "    print(f\"\\nSe crearon {total_df} DataFrames en total.\")\n",
    "    \n",
    "    if not dataframes:\n",
    "        print(\"No se cargaron archivos en la carpeta especificada.\")\n",
    "    return dataframes\n",
    "\n",
    "def agregar_nombre_a_dataframes(dataframes):\n",
    "    \"\"\"\n",
    "    Agrega una columna adicional a cada DataFrame con su nombre (clave del diccionario).\n",
    "    \"\"\"\n",
    "    for name, df in dataframes.items():\n",
    "        df[\"nombre_dataframe\"] = name  # Agrega una columna con el nombre del DataFrame\n",
    "    print(\"Se agregó la columna 'nombre_dataframe' a todos los DataFrames.\")\n",
    "\n",
    "def mostrar_primeras_filas(dataframes):\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Primeras filas de {name}:\")\n",
    "        print(df.head())\n",
    "        print(\"\\n---\\n\")\n",
    "        # Puedes quitar el \"break\" si deseas mostrar todos los DataFrames\n",
    "        break\n",
    "\n",
    "# Ejecución del script\n",
    "ruta = obtener_ruta_carpeta()\n",
    "if ruta:\n",
    "    # Incluye las extensiones .NEG y .VAL\n",
    "    dataframes = cargar_archivos_a_dataframe(ruta, extensiones=[\".NEG\", \".VAL\"])\n",
    "    if dataframes:\n",
    "        # Agregar el nombre del DataFrame como columna\n",
    "        agregar_nombre_a_dataframes(dataframes)\n",
    "        # Mostrar las primeras filas de los DataFrames\n",
    "        mostrar_primeras_filas(dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04365f-26ba-47a8-8a5b-90321f60776d",
   "metadata": {},
   "source": [
    "Revisando las dimenciones de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3316c4b7-eafc-4652-84ca-908418d3b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Si df_1 está en el diccionario 'dataframes', lo puedes acceder así:\n",
    "\n",
    "#dataframes['df_22112019'].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11893e78-333d-459e-9b4a-c57ebdfe436d",
   "metadata": {},
   "source": [
    "## 3.1 Searching the shape of all dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "87efeeba-f798-4846-8235-49d1907d6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name  Row  Cols\n",
      "df_04082023: 1240  22\n",
      "df_05052023: 106  22\n",
      "df_06012023: 85  22\n",
      "df_06102023: 305  22\n",
      "df_07072023: 64  22\n",
      "df_07122023: 125  22\n",
      "df_09062023: 115  22\n",
      "df_10022023: 191  22\n",
      "df_10032023: 104  22\n",
      "df_10112023: 1571  22\n",
      "df_11082023: 2248  22\n",
      "df_12052023: 171  22\n",
      "df_13012023: 195  22\n",
      "df_13102023: 566  22\n",
      "df_14042023: 92  22\n",
      "df_14072023: 20  22\n",
      "df_15092023: 307  22\n",
      "df_15122023: 332  22\n",
      "df_16062023: 56  22\n",
      "df_17022023: 105  22\n",
      "df_17032023: 41  22\n",
      "df_17112023: 57  22\n",
      "df_18082023: 79  22\n",
      "df_19052023: 106  22\n",
      "df_20012023: 54  22\n",
      "df_20102023: 846  22\n",
      "df_21042023: 184  22\n",
      "df_21072023: 144  22\n",
      "df_22092023: 271  22\n",
      "df_22122023: 258  22\n",
      "df_23062023: 57  22\n",
      "df_24032023: 171  22\n",
      "df_24112023: 393  22\n",
      "df_25082023: 938  22\n",
      "\n",
      "Total de registros en todos los DataFrames: 11597\n"
     ]
    }
   ],
   "source": [
    "print('Name  Row  Cols')\n",
    "\n",
    "# Lista para almacenar la cantidad de filas\n",
    "row_counts = []\n",
    "\n",
    "# Recorremos los DataFrames en el diccionario\n",
    "for name, df in dataframes.items():\n",
    "    rows, cols = df.shape\n",
    "    row_counts.append(rows)  # Añadimos la cantidad de filas a la lista\n",
    "    print(f\"{name}: {rows}  {cols}\")\n",
    "\n",
    "# Calculamos el total de filas\n",
    "total_rows = sum(row_counts)\n",
    "print(f\"\\nTotal de registros en todos los DataFrames: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013fb86-38f3-485b-864f-0e7b961b4000",
   "metadata": {},
   "source": [
    "# 4. Creating the original Merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "182a1b4f-d774-419c-b88b-4fd0d9ba899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame 'neg_all_2023': (11597, 22)\n",
      "Primeras 5 filas del DataFrame 'neg_all_2023':\n",
      "   col_1   col_2 col_3           col_4        col_5        col_6    col_7  \\\n",
      "0      2  EPS025    TI      1006450972       MONTES         DIAZ    LUZIO   \n",
      "1      6  EPS025    RC      1115916352      PONGUTA  BALLESTEROS      ZOE   \n",
      "2     10  EPS025    TI      1116662294     MANTILLA    GUTIERREZ   DANIEL   \n",
      "3     11  EPS025    TI      1117322442        AMARO    RODRIGUEZ    PEDRO   \n",
      "4     14  EPS025    CN  23071210557566  MENDIVELSON          PAN  HIJO DE   \n",
      "\n",
      "      col_8       col_9  col_10  ...      col_13 col_14      col_15  \\\n",
      "0    FABIAN  10/03/2001      85  ...  01/06/2023     CC  1006450972   \n",
      "1     MAHIA  23/07/2021      85  ...  21/07/2023     RC  1006405282   \n",
      "2       NaN  14/04/2003      85  ...  01/06/2023     CC  1116662294   \n",
      "3  SANTIAGO  15/02/2005      85  ...  01/05/2023     CC  1117322442   \n",
      "4       NaN  14/07/2023      85  ...  24/07/2023     RC  1222144572   \n",
      "\n",
      "       col_16 col_17 col_18 col_19 col_20  \\\n",
      "0  10/03/2001      0    NaN    NaN    NaN   \n",
      "1  23/07/2021      1    NaN    NaN    NaN   \n",
      "2  14/04/2003      0    NaN    NaN    NaN   \n",
      "3  15/02/2005      0    NaN    NaN    NaN   \n",
      "4  14/07/2023      0    NaN    NaN    NaN   \n",
      "\n",
      "                                              col_21  nombre_dataframe  \n",
      "0                                    GN0169(||||||);       df_04082023  \n",
      "1  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...       df_04082023  \n",
      "2                                    GN0169(||||||);       df_04082023  \n",
      "3  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...       df_04082023  \n",
      "4  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...       df_04082023  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir el número de columnas deseadas\n",
    "num_columnas = 22\n",
    "\n",
    "# Asegurar que todos los DataFrames tengan exactamente el mismo número de columnas\n",
    "dataframes_alineados = {name: df.iloc[:, :num_columnas] for name, df in dataframes.items()}\n",
    "\n",
    "# Definir un nombre fijo para el DataFrame combinado\n",
    "#nombre_merged = \"merged_meses\"\n",
    "\n",
    "# Combinar todos los DataFrames alineados, sin crear nuevas columnas\n",
    "globals()[nombre_merged] = pd.concat(dataframes_alineados.values(), axis=0, ignore_index=True)\n",
    "\n",
    "# Mostrar el shape del DataFrame combinado\n",
    "print(f\"Shape del DataFrame '{nombre_merged}': {globals()[nombre_merged].shape}\")\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(f\"Primeras 5 filas del DataFrame '{nombre_merged}':\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaf42e-1204-464f-a42c-c5257d3ad18a",
   "metadata": {},
   "source": [
    "## 4.1 Checking the Merged's Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c5952f74-cd8f-40cf-98fc-4bc809e40306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',\n",
      "       'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15',\n",
      "       'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21',\n",
      "       'nombre_dataframe'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(globals()[nombre_merged].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e6fc19-f11f-4ce4-8726-7991c0f41ef0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4.2 Cleaning the Merged's colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "3b1dd52a-c6b5-49ac-9229-bb9421ddc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col_2 col_3           col_4       col_9  col_10  col_11 col_12  \\\n",
      "0  EPS025    TI      1006450972  10/03/2001      85     430    N01   \n",
      "1  EPS025    RC      1115916352  23/07/2021      85     410    N01   \n",
      "2  EPS025    TI      1116662294  14/04/2003      85     430    N01   \n",
      "3  EPS025    TI      1117322442  15/02/2005      85     230    N01   \n",
      "4  EPS025    CN  23071210557566  14/07/2023      85     230    N01   \n",
      "\n",
      "       col_13 nombre_dataframe  \\\n",
      "0  01/06/2023      df_04082023   \n",
      "1  21/07/2023      df_04082023   \n",
      "2  01/06/2023      df_04082023   \n",
      "3  01/05/2023      df_04082023   \n",
      "4  24/07/2023      df_04082023   \n",
      "\n",
      "                                              col_21  \n",
      "0                                    GN0169(||||||);  \n",
      "1  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  \n",
      "2                                    GN0169(||||||);  \n",
      "3  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...  \n",
      "4  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...  \n"
     ]
    }
   ],
   "source": [
    "# Selecciona las columnas que deseas mantener\n",
    "globals()[nombre_merged] = globals()[nombre_merged][['col_2', 'col_3','col_4','col_9', 'col_10', 'col_11', 'col_12', 'col_13','nombre_dataframe','col_21']]\n",
    "#union_2019 = union_2019[['col_2', 'col_3','col_8','col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_21']]\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b40c1-e761-4f60-83f1-e755d8f825c7",
   "metadata": {},
   "source": [
    "## 4.3 Renaming column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ddbfc2c-f526-4d60-b771-0d686f55bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colum1 colum2          colum3      colum4  colum5  colum6 colum7  \\\n",
      "0  EPS025     TI      1006450972  10/03/2001      85     430    N01   \n",
      "1  EPS025     RC      1115916352  23/07/2021      85     410    N01   \n",
      "2  EPS025     TI      1116662294  14/04/2003      85     430    N01   \n",
      "3  EPS025     TI      1117322442  15/02/2005      85     230    N01   \n",
      "4  EPS025     CN  23071210557566  14/07/2023      85     230    N01   \n",
      "\n",
      "       colum8       colum9                                            colum10  \n",
      "0  01/06/2023  df_04082023                                    GN0169(||||||);  \n",
      "1  21/07/2023  df_04082023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  \n",
      "2  01/06/2023  df_04082023                                    GN0169(||||||);  \n",
      "3  01/05/2023  df_04082023  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...  \n",
      "4  24/07/2023  df_04082023  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...  \n"
     ]
    }
   ],
   "source": [
    "# Obtiene la cantidad de columnas en el DataFrame\n",
    "num_columns = globals()[nombre_merged].shape[1]\n",
    "\n",
    "# Genera nuevos nombres de columnas: 'colum1', 'colum2', ..., 'columnN'\n",
    "new_columns = [f'colum{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Asigna los nuevos nombres de columnas al DataFrame\n",
    "globals()[nombre_merged].columns = new_columns\n",
    "\n",
    "# Verifica el resultado\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "94ad6470-ddf6-4886-bae2-8418b42e837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colum1     object\n",
       "colum2     object\n",
       "colum3     object\n",
       "colum4     object\n",
       "colum5      int64\n",
       "colum6      int64\n",
       "colum7     object\n",
       "colum8     object\n",
       "colum9     object\n",
       "colum10    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ef8d7b-afae-4b65-8cd8-035da21b5c5a",
   "metadata": {},
   "source": [
    "## 4.4 Looking for the column with df_ and converting to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c9b562d8-46b0-40e7-90a2-8700fe16436d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformación realizada directamente en el DataFrame: neg_all_2023\n",
      "   colum1 colum2          colum3      colum4 colum5 colum6 colum7      colum8  \\\n",
      "0  EPS025     TI      1006450972  10/03/2001     85    430    N01  01/06/2023   \n",
      "1  EPS025     RC      1115916352  23/07/2021     85    410    N01  21/07/2023   \n",
      "2  EPS025     TI      1116662294  14/04/2003     85    430    N01  01/06/2023   \n",
      "3  EPS025     TI      1117322442  15/02/2005     85    230    N01  01/05/2023   \n",
      "4  EPS025     CN  23071210557566  14/07/2023     85    230    N01  24/07/2023   \n",
      "\n",
      "       colum9                                            colum10  \n",
      "0  04/08/2023                                    GN0169(||||||);  \n",
      "1  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  \n",
      "2  04/08/2023                                    GN0169(||||||);  \n",
      "3  04/08/2023  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...  \n",
      "4  04/08/2023  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...  \n"
     ]
    }
   ],
   "source": [
    "#import re  # Importamos para manejar expresiones regulares\n",
    "\n",
    "# Procesamos directamente el DataFrame en globals()\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    # Modificamos las celdas de cada columna según el patrón\n",
    "    globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(str).apply(\n",
    "        lambda x: re.sub(r'^df_(\\d{2})(\\d{2})(\\d{4})$', r'\\1/\\2/\\3', x) \n",
    "        if 'df_' in x else x\n",
    "    )\n",
    "\n",
    "# Confirmamos que la transformación se realizó\n",
    "print(f\"Transformación realizada directamente en el DataFrame: {nombre_merged}\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865d1ce1-badb-4811-8431-ec8786257490",
   "metadata": {},
   "source": [
    "## 4.5 Change type of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "8746a305-3ada-4c4e-b954-0db5496437e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversión de tipos completada en el DataFrame: neg_all_2023\n"
     ]
    }
   ],
   "source": [
    "# Recorremos cada columna del DataFrame\n",
    "for column in globals()[nombre_merged].columns:\n",
    "    # Convertir a entero si todos los valores son numéricos\n",
    "    if globals()[nombre_merged][column].apply(lambda x: str(x).isdigit()).all():\n",
    "        globals()[nombre_merged][column] = globals()[nombre_merged][column].astype(int)\n",
    "    \n",
    "    # Convertir a string con formato DD/MM/YYYY si los valores están en formato de fecha\n",
    "    else:\n",
    "        try:\n",
    "            # Convertir a datetime primero\n",
    "            globals()[nombre_merged][column] = pd.to_datetime(\n",
    "                globals()[nombre_merged][column], format='%d/%m/%Y', errors='raise'\n",
    "            )\n",
    "            # Convertir a string con formato DD/MM/YYYY\n",
    "            globals()[nombre_merged][column] = globals()[nombre_merged][column].dt.strftime('%d/%m/%Y')\n",
    "        except:\n",
    "            pass  # Si no es fecha, se deja igual\n",
    "\n",
    "print(f\"Conversión de tipos completada en el DataFrame: {nombre_merged}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b85fec53-f18e-4894-96ef-2d02717155cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colum1     object\n",
       "colum2     object\n",
       "colum3     object\n",
       "colum4     object\n",
       "colum5      int32\n",
       "colum6      int32\n",
       "colum7     object\n",
       "colum8     object\n",
       "colum9     object\n",
       "colum10    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "fd72d069-04ec-46b8-adf0-e5f15c94c46c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>colum1</th>\n",
       "      <th>colum2</th>\n",
       "      <th>colum3</th>\n",
       "      <th>colum4</th>\n",
       "      <th>colum5</th>\n",
       "      <th>colum6</th>\n",
       "      <th>colum7</th>\n",
       "      <th>colum8</th>\n",
       "      <th>colum9</th>\n",
       "      <th>colum10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006450972</td>\n",
       "      <td>10/03/2001</td>\n",
       "      <td>85</td>\n",
       "      <td>430</td>\n",
       "      <td>N01</td>\n",
       "      <td>01/06/2023</td>\n",
       "      <td>04/08/2023</td>\n",
       "      <td>GN0169(||||||);</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>RC</td>\n",
       "      <td>1115916352</td>\n",
       "      <td>23/07/2021</td>\n",
       "      <td>85</td>\n",
       "      <td>410</td>\n",
       "      <td>N01</td>\n",
       "      <td>21/07/2023</td>\n",
       "      <td>04/08/2023</td>\n",
       "      <td>GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   colum1 colum2      colum3      colum4  colum5  colum6 colum7      colum8  \\\n",
       "0  EPS025     TI  1006450972  10/03/2001      85     430    N01  01/06/2023   \n",
       "1  EPS025     RC  1115916352  23/07/2021      85     410    N01  21/07/2023   \n",
       "\n",
       "       colum9                                            colum10  \n",
       "0  04/08/2023                                    GN0169(||||||);  \n",
       "1  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cdf3c7e-67aa-4e11-802a-1a9779cf8adc",
   "metadata": {},
   "source": [
    "## 4.6 Renaming names Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "8795dbe8-6c4e-4627-a900-43287c8605c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar las columnas\n",
    "globals()[nombre_merged].columns = ['cod_reg', 'tip_doc', 'doc', 'fech_nac', 'dep', 'mun', 'nov', 'fech_nov', 'fecha_rep', 'observs']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "f2383ada-31cc-4975-b319-4cf7f718518e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11597, 10)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "83a6cf72-9bd0-4b3a-96e3-63f76391bed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cod_reg</th>\n",
       "      <th>tip_doc</th>\n",
       "      <th>doc</th>\n",
       "      <th>fech_nac</th>\n",
       "      <th>dep</th>\n",
       "      <th>mun</th>\n",
       "      <th>nov</th>\n",
       "      <th>fech_nov</th>\n",
       "      <th>fecha_rep</th>\n",
       "      <th>observs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1006450972</td>\n",
       "      <td>10/03/2001</td>\n",
       "      <td>85</td>\n",
       "      <td>430</td>\n",
       "      <td>N01</td>\n",
       "      <td>01/06/2023</td>\n",
       "      <td>04/08/2023</td>\n",
       "      <td>GN0169(||||||);</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EPS025</td>\n",
       "      <td>RC</td>\n",
       "      <td>1115916352</td>\n",
       "      <td>23/07/2021</td>\n",
       "      <td>85</td>\n",
       "      <td>410</td>\n",
       "      <td>N01</td>\n",
       "      <td>21/07/2023</td>\n",
       "      <td>04/08/2023</td>\n",
       "      <td>GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cod_reg tip_doc         doc    fech_nac  dep  mun  nov    fech_nov  \\\n",
       "0  EPS025      TI  1006450972  10/03/2001   85  430  N01  01/06/2023   \n",
       "1  EPS025      RC  1115916352  23/07/2021   85  410  N01  21/07/2023   \n",
       "\n",
       "    fecha_rep                                            observs  \n",
       "0  04/08/2023                                    GN0169(||||||);  \n",
       "1  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  "
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2d17aa91-44bf-477d-bd43-af92afefaa02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cod_reg      object\n",
       "tip_doc      object\n",
       "doc          object\n",
       "fech_nac     object\n",
       "dep           int32\n",
       "mun           int32\n",
       "nov          object\n",
       "fech_nov     object\n",
       "fecha_rep    object\n",
       "observs      object\n",
       "dtype: object"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "globals()[nombre_merged].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6012103b",
   "metadata": {},
   "source": [
    "# 4.7 Counting Glosses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0afb88e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para contar el número de glosas en un registro\n",
    "def count_glosas(observs):\n",
    "    # Asegúrate de trabajar con cadenas\n",
    "    if isinstance(observs, str):\n",
    "        return len(re.findall(r'GN\\d{4}', observs))\n",
    "    # Si no es una cadena, devolver 0\n",
    "    return 0\n",
    "\n",
    "# Aplicar la función a la columna 'observs' y crear la nueva columna 'No_Glosas'\n",
    "globals()[nombre_merged][\"No_Glosas\"] = globals()[nombre_merged][\"observs\"].apply(count_glosas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dea5bf3-d929-44a9-9c75-7d5e227ace18",
   "metadata": {},
   "source": [
    "## 4.7.1 Divide las glosas que estan concatenadas en 1 solo registro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2bf3ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 10 filas del DataFrame procesado:\n",
      "  cod_reg tip_doc             doc    fech_nac  dep  mun  nov    fech_nov  \\\n",
      "0  EPS025      TI      1006450972  10/03/2001   85  430  N01  01/06/2023   \n",
      "1  EPS025      TI      1006450972  10/03/2001   85  430  N01  01/06/2023   \n",
      "2  EPS025      RC      1115916352  23/07/2021   85  410  N01  21/07/2023   \n",
      "3  EPS025      RC      1115916352  23/07/2021   85  410  N01  21/07/2023   \n",
      "4  EPS025      TI      1116662294  14/04/2003   85  430  N01  01/06/2023   \n",
      "5  EPS025      TI      1116662294  14/04/2003   85  430  N01  01/06/2023   \n",
      "6  EPS025      TI      1117322442  15/02/2005   85  230  N01  01/05/2023   \n",
      "7  EPS025      TI      1117322442  15/02/2005   85  230  N01  01/05/2023   \n",
      "8  EPS025      CN  23071210557566  14/07/2023   85  230  N01  24/07/2023   \n",
      "9  EPS025      CN  23071210557566  14/07/2023   85  230  N01  24/07/2023   \n",
      "\n",
      "    fecha_rep                                            observs  No_Glosas  \\\n",
      "0  04/08/2023                                    GN0169(||||||);          1   \n",
      "1  04/08/2023                                    GN0169(||||||);          1   \n",
      "2  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...          1   \n",
      "3  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...          1   \n",
      "4  04/08/2023                                    GN0169(||||||);          1   \n",
      "5  04/08/2023                                    GN0169(||||||);          1   \n",
      "6  04/08/2023  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...          1   \n",
      "7  04/08/2023  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...          1   \n",
      "8  04/08/2023  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...          1   \n",
      "9  04/08/2023  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...          1   \n",
      "\n",
      "                                 observaciones_split  \n",
      "0                                     GN0169(||||||)  \n",
      "1                                                     \n",
      "2  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...  \n",
      "3                                                     \n",
      "4                                     GN0169(||||||)  \n",
      "5                                                     \n",
      "6  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...  \n",
      "7                                                     \n",
      "8  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...  \n",
      "9                                                     \n",
      "\n",
      "Total de filas antes de separar: 27737\n",
      "Total de filas después de separar: 27737\n"
     ]
    }
   ],
   "source": [
    "# 1. Crear nueva columna separando por punto y coma\n",
    "globals()[nombre_merged]['observaciones_split'] = globals()[nombre_merged]['observs'].str.split(';')\n",
    "\n",
    "# 2. Usar explode para crear una fila por cada elemento\n",
    "df_resultado = globals()[nombre_merged].explode('observaciones_split')\n",
    "\n",
    "# 3. Resetear el índice\n",
    "df_resultado = df_resultado.reset_index(drop=True)\n",
    "\n",
    "# 4. Guardar el resultado\n",
    "globals()[nombre_merged] = df_resultado\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"\\nPrimeras 10 filas del DataFrame procesado:\")\n",
    "print(df_resultado.head(10))\n",
    "\n",
    "# Mostrar conteo de filas\n",
    "print(f\"\\nTotal de filas antes de separar: {len(globals()[nombre_merged])}\")\n",
    "print(f\"Total de filas después de separar: {len(df_resultado)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fb2c6a-e435-4f28-9663-3ccf141d1834",
   "metadata": {},
   "source": [
    "## 4.7.2 Creating new files for every glosa per User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0c2bb6d6-406b-4d01-800d-8212a8a95462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 10 filas después de separar GN y glosas:\n",
      "  observaciones_split                                           obs_glos\n",
      "0              GN0169                                           (||||||)\n",
      "1                                                                       \n",
      "2              GN0169  (PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO APELLID...\n",
      "3                                                                       \n",
      "4              GN0169                                           (||||||)\n",
      "5                                                                       \n",
      "6              GN0169       (||||FECHA NACIMIENTO|18/02/2005|15/02/2005)\n",
      "7                                                                       \n",
      "8              GN0031  (RC|1222144572|CHAPARRO|MENDIVELSON|AXEL|JOEL|...\n",
      "9                                                                       \n",
      "\n",
      "Ejemplos de separaciones realizadas:\n",
      "      observaciones_split                                      obs_glos\n",
      "14352                                                                  \n",
      "16398              GN0084                          (cnd_afl|01/11/2023)\n",
      "5561               GN0009  (C|EPSC25|01/10/2022|85|410|C|AC|06/03/2023)\n",
      "10008              GN0042                                           (2)\n",
      "18137                                                                  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# 1. Crear la nueva columna para las glosas\n",
    "globals()[nombre_merged]['obs_glos'] = ''\n",
    "\n",
    "# 2. Función para separar GN y glosa\n",
    "def separar_gn_glosa(texto):\n",
    "    if isinstance(texto, str):\n",
    "        # Buscar específicamente GN seguido de exactamente 4 dígitos\n",
    "        match = re.match(r'(GN\\d{4})(.*)', texto.strip())\n",
    "        if match:\n",
    "            return match.group(1), match.group(2).strip()\n",
    "    return texto, ''\n",
    "\n",
    "# 3. Aplicar la separación\n",
    "for idx, row in globals()[nombre_merged].iterrows():\n",
    "    gn, glosa = separar_gn_glosa(row['observaciones_split'])\n",
    "    globals()[nombre_merged].at[idx, 'observaciones_split'] = gn\n",
    "    globals()[nombre_merged].at[idx, 'obs_glos'] = glosa\n",
    "\n",
    "# 4. Mostrar el resultado\n",
    "print(\"\\nPrimeras 10 filas después de separar GN y glosas:\")\n",
    "print(globals()[nombre_merged][['observaciones_split', 'obs_glos']].head(10))\n",
    "\n",
    "# 5. Mostrar algunos ejemplos de las separaciones realizadas\n",
    "print(\"\\nEjemplos de separaciones realizadas:\")\n",
    "muestra = globals()[nombre_merged][['observaciones_split', 'obs_glos']].sample(5)\n",
    "print(muestra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660be9e5-a09e-444c-89b8-cd1387684101",
   "metadata": {},
   "source": [
    "## 4.7.2 Deleting Nan dates in observaciones_split column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1ca5dc64-1f8c-43d8-a9df-a0c8972ed274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 5 filas después de limpiar:\n",
      "  cod_reg tip_doc             doc    fech_nac  dep  mun  nov    fech_nov  \\\n",
      "0  EPS025      TI      1006450972  10/03/2001   85  430  N01  01/06/2023   \n",
      "2  EPS025      RC      1115916352  23/07/2021   85  410  N01  21/07/2023   \n",
      "4  EPS025      TI      1116662294  14/04/2003   85  430  N01  01/06/2023   \n",
      "6  EPS025      TI      1117322442  15/02/2005   85  230  N01  01/05/2023   \n",
      "8  EPS025      CN  23071210557566  14/07/2023   85  230  N01  24/07/2023   \n",
      "\n",
      "    fecha_rep                                            observs  No_Glosas  \\\n",
      "0  04/08/2023                                    GN0169(||||||);          1   \n",
      "2  04/08/2023  GN0169(PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO A...          1   \n",
      "4  04/08/2023                                    GN0169(||||||);          1   \n",
      "6  04/08/2023  GN0169(||||FECHA NACIMIENTO|18/02/2005|15/02/2...          1   \n",
      "8  04/08/2023  GN0031(RC|1222144572|CHAPARRO|MENDIVELSON|AXEL...          1   \n",
      "\n",
      "  observaciones_split                                           obs_glos  \n",
      "0              GN0169                                           (||||||)  \n",
      "2              GN0169  (PRIMER APELLIDO|RIVAS|PONGUTA|SEGUNDO APELLID...  \n",
      "4              GN0169                                           (||||||)  \n",
      "6              GN0169       (||||FECHA NACIMIENTO|18/02/2005|15/02/2005)  \n",
      "8              GN0031  (RC|1222144572|CHAPARRO|MENDIVELSON|AXEL|JOEL|...  \n",
      "\n",
      "Total de filas después de limpiar: 16144\n"
     ]
    }
   ],
   "source": [
    "# Eliminar valores vacíos y espacios en blanco\n",
    "df_resultado = globals()[nombre_merged]\n",
    "df_resultado = df_resultado[df_resultado['observaciones_split'].notna()]  # Elimina NaN\n",
    "df_resultado = df_resultado[df_resultado['observaciones_split'].str.strip() != '']  # Elimina strings vacíos o solo espacios\n",
    "\n",
    "# Guardar el resultado limpio\n",
    "globals()[nombre_merged] = df_resultado\n",
    "\n",
    "# Mostrar resultado\n",
    "print(\"\\nPrimeras 5 filas después de limpiar:\")\n",
    "print(df_resultado.head())\n",
    "\n",
    "print(f\"\\nTotal de filas después de limpiar: {len(df_resultado)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2704203b-8cb3-4e00-aa3e-6e22a3990708",
   "metadata": {},
   "source": [
    "# 5. DOWNLADING FENITIVE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "40f20b50-cb2a-44fb-a1b7-a8f98a2bc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo se ha guardado correctamente en: C:\\Users\\carlo\\Downloads\\neg_all_2023.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Guardar el DataFrame como un archivo Excel\n",
    "globals()[nombre_merged].to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo se ha guardado correctamente en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ba6f36-1e61-45ba-91f1-11fba321c5fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Notes\n",
    "\n",
    "Colega hasta aqui se exporta un archivo en formato xlx, esta pendiente que sumerced agregue el paso de tratamiento para la columna de observaciones, la idea seria que lo numere y lo agregue aqui. por otra parte si quiere optimizar este codigo es libre de hacerlo, estoy abierto a cualquier sugerencia para mejorar. Gracias"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
