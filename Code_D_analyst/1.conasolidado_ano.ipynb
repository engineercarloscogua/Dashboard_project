{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "926b1041-c407-4321-bb2e-93807f26ecf9",
   "metadata": {},
   "source": [
    "Librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd8e698-ee7d-4fb2-b8f0-4d51646bfb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "87b9caee-5059-4079-9d07-02ba1cfcd495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes):  \"C:\\Users\\carlo\\OneDrive\\Documentos\\dataP\\MUNICIPIOS 2019\\2019\\NEG\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La ruta ingresada es: C:/Users/carlo/OneDrive/Documentos/dataP/MUNICIPIOS 2019/2019/NEG\n",
      "Archivo NSEPS02504102019.NEG cargado como df_1\n",
      "Archivo NSEPS02505042019.NEG cargado como df_2\n",
      "Archivo NSEPS02505072019.NEG cargado como df_3\n",
      "Archivo NSEPS02506092019.NEG cargado como df_4\n",
      "Archivo NSEPS02507062019.NEG cargado como df_5\n",
      "Archivo NSEPS02508022019.NEG cargado como df_6\n",
      "Archivo NSEPS02508032019.NEG cargado como df_7\n",
      "Archivo NSEPS02508112019.NEG cargado como df_8\n",
      "Archivo NSEPS02509082019.NEG cargado como df_9\n",
      "Archivo NSEPS02510052019.NEG cargado como df_10\n",
      "Archivo NSEPS02511012019.NEG cargado como df_11\n",
      "Archivo NSEPS02511102019.NEG cargado como df_12\n",
      "Archivo NSEPS02512042019.NEG cargado como df_13\n",
      "Archivo NSEPS02512072019.NEG cargado como df_14\n",
      "Archivo NSEPS02513092019.NEG cargado como df_15\n",
      "Archivo NSEPS02513122019.NEG cargado como df_16\n",
      "Archivo NSEPS02514062019.NEG cargado como df_17\n",
      "Archivo NSEPS02515022019.NEG cargado como df_18\n",
      "Archivo NSEPS02515032019.NEG cargado como df_19\n",
      "Archivo NSEPS02515112019.NEG cargado como df_20\n",
      "Archivo NSEPS02516082019.NEG cargado como df_21\n",
      "Archivo NSEPS02517052019.NEG cargado como df_22\n",
      "Archivo NSEPS02518012019.NEG cargado como df_23\n",
      "Archivo NSEPS02518102019.NEG cargado como df_24\n",
      "Archivo NSEPS02519072019.NEG cargado como df_25\n",
      "Archivo NSEPS02520092019.NEG cargado como df_26\n",
      "Archivo NSEPS02520122019.NEG cargado como df_27\n",
      "Archivo NSEPS02521062019.NEG cargado como df_28\n",
      "Archivo NSEPS02522022019.NEG cargado como df_29\n",
      "Archivo NSEPS02522032019.NEG cargado como df_30\n",
      "Archivo NSEPS02522112019.NEG cargado como df_31\n",
      "Archivo NSEPS02523082019.NEG cargado como df_32\n",
      "Archivo NSEPS02524052019.NEG cargado como df_33\n",
      "Archivo NSEPS02525012019.NEG cargado como df_34\n",
      "Archivo NSEPS02525102019.NEG cargado como df_35\n"
     ]
    }
   ],
   "source": [
    "# Función para solicitar la ruta de la carpeta al usuario\n",
    "def obtener_ruta_carpeta():\n",
    "    # Solicitar la ruta de la carpeta al usuario\n",
    "    folder_path = input('Por favor, ingresa la ruta de la carpeta (incluyendo las comillas si están presentes): ')\n",
    "    \n",
    "    # Eliminar las comillas dobles alrededor de la ruta, si las hay\n",
    "    folder_path = folder_path.strip('\"')\n",
    "    \n",
    "    # Reemplazar las barras invertidas con barras normales\n",
    "    folder_path = folder_path.replace(\"\\\\\", \"/\")\n",
    "    \n",
    "    return folder_path  # Retorna la ruta corregida\n",
    "\n",
    "# Función para leer los archivos y almacenarlos en un diccionario de DataFrames\n",
    "def cargar_archivos_a_dataframe(folder_path):\n",
    "    dataframes = {}\n",
    "    \n",
    "    # Itera sobre todos los archivos en la carpeta\n",
    "    for i, filename in enumerate(os.listdir(folder_path), start=1):\n",
    "        if filename.endswith(\".NEG\"):  # Filtra solo los archivos con extensión .NEG\n",
    "            file_path = os.path.join(folder_path, filename)  # Construye la ruta completa\n",
    "            try:\n",
    "                # Lee el archivo como un DataFrame sin nombres de columnas\n",
    "                df = pd.read_csv(file_path, sep=\",\", encoding=\"latin-1\", header=None)\n",
    "                \n",
    "                # Asigna nombres de columnas numerados (col_1, col_2, ..., col_n)\n",
    "                df.columns = [f\"col_{j+1}\" for j in range(df.shape[1])]\n",
    "                \n",
    "                # Almacena el DataFrame en el diccionario con un nombre dinámico\n",
    "                dataframes[f\"df_{i}\"] = df\n",
    "                print(f\"Archivo {filename} cargado como df_{i}\")\n",
    "            except Exception as e:\n",
    "                print(f\"No se pudo leer el archivo {filename}: {e}\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Función para mostrar las primeras filas de los DataFrames cargados\n",
    "def mostrar_primeras_filas(dataframes):\n",
    "    # Mostrar las primeras filas de uno de los DataFrames para verificar\n",
    "    for name, df in dataframes.items():\n",
    "        print(f\"Primeras filas de {name}:\")\n",
    "        print(df.head())\n",
    "        break  # Muestra solo el primer DataFrame como ejemplo\n",
    "\n",
    "# Llamada a la función para obtener la ruta\n",
    "ruta = obtener_ruta_carpeta()\n",
    "print(f\"La ruta ingresada es: {ruta}\")\n",
    "\n",
    "# Llamada a la función para cargar los archivos en un diccionario de DataFrames\n",
    "dataframes = cargar_archivos_a_dataframe(ruta)\n",
    "\n",
    "# Llamada a la función para mostrar las primeras filas de los DataFrames cargados\n",
    "#mostrar_primeras_filas(dataframes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d04365f-26ba-47a8-8a5b-90321f60776d",
   "metadata": {},
   "source": [
    "Revisando las dimenciones de los dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "87efeeba-f798-4846-8235-49d1907d6b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name Row  Cols\n",
      "df_1: (289, 21)\n",
      "df_2: (345, 21)\n",
      "df_3: (267, 21)\n",
      "df_4: (793, 21)\n",
      "df_5: (234, 21)\n",
      "df_6: (242, 21)\n",
      "df_7: (703, 21)\n",
      "df_8: (555, 21)\n",
      "df_9: (2105, 21)\n",
      "df_10: (402, 21)\n",
      "df_11: (227, 21)\n",
      "df_12: (359, 21)\n",
      "df_13: (437, 21)\n",
      "df_14: (225, 21)\n",
      "df_15: (194, 21)\n",
      "df_16: (227, 21)\n",
      "df_17: (219, 21)\n",
      "df_18: (394, 21)\n",
      "df_19: (491, 21)\n",
      "df_20: (553, 21)\n",
      "df_21: (229, 21)\n",
      "df_22: (483, 21)\n",
      "df_23: (264, 21)\n",
      "df_24: (413, 21)\n",
      "df_25: (229, 21)\n",
      "df_26: (199, 21)\n",
      "df_27: (199, 21)\n",
      "df_28: (205, 21)\n",
      "df_29: (402, 21)\n",
      "df_30: (298, 21)\n",
      "df_31: (305, 21)\n",
      "df_32: (168, 21)\n",
      "df_33: (214, 21)\n",
      "df_34: (235, 21)\n",
      "df_35: (273, 21)\n"
     ]
    }
   ],
   "source": [
    "print('Name Row  Cols')\n",
    "for name, df in dataframes.items():\n",
    "    print(f\"{name}: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "182a1b4f-d774-419c-b88b-4fd0d9ba899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "¿Cómo deseas llamar al DataFrame combinado?  merge2019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape del DataFrame 'merge2019': (13377, 21)\n",
      "Primeras 5 filas del DataFrame 'merge2019':\n",
      "   col_1   col_2 col_3        col_4       col_5        col_6     col_7  \\\n",
      "0     16  EPS025    TI   1006413607   RODRIGUEZ    CASTAÑEDA      NANI   \n",
      "1     86  EPS025    TI   1006559623  CHAMARRAVI  GUACARAPARE   KINNEDY   \n",
      "2    133  EPS025    TI   1010107558       RIVAS      ALVAREZ       YAN   \n",
      "3    422  EPS025    TI  90010379279     MARQUEZ    HERNANDEZ  PATRICIA   \n",
      "4    477  EPS025    TI   1006450537       JAZPE      BARRETO     JULIO   \n",
      "\n",
      "      col_8       col_9  col_10  ...  col_12      col_13 col_14      col_15  \\\n",
      "0   MAYERLI  10/07/2001      85  ...     N01  30/09/2019     CC  1006413607   \n",
      "1  BERNARDO  30/05/2000      85  ...     N01  30/09/2019     CC  1006559623   \n",
      "2    CARLOS  26/11/2000      85  ...     N01  30/09/2019     CC  1010107558   \n",
      "3       NaN  03/01/1990      85  ...     N01  30/09/2019     CC  1118542994   \n",
      "4    DANIEL  07/06/2000      85  ...     N01  30/09/2019     CC  1006450537   \n",
      "\n",
      "       col_16 col_17  col_18  col_19  col_20  \\\n",
      "0  10/07/2001    0.0     NaN     NaN     NaN   \n",
      "1  30/05/2000    0.0     NaN     NaN     NaN   \n",
      "2  26/11/2000    0.0     NaN     NaN     NaN   \n",
      "3  03/01/1990    0.0     NaN     NaN     NaN   \n",
      "4  07/06/2000    0.0     NaN     NaN     NaN   \n",
      "\n",
      "                                              col_21  \n",
      "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Definir el número de columnas deseadas\n",
    "num_columnas = 21\n",
    "\n",
    "# Asegurar que todos los DataFrames tengan exactamente el mismo número de columnas\n",
    "dataframes_alineados = {name: df.iloc[:, :num_columnas] for name, df in dataframes.items()}\n",
    "\n",
    "# Preguntar al usuario cómo desea llamar al DataFrame combinado\n",
    "nombre_merged = input(\"¿Cómo deseas llamar al DataFrame combinado? \")\n",
    "\n",
    "# Combinar todos los DataFrames alineados, sin crear nuevas columnas\n",
    "globals()[nombre_merged] = pd.concat(dataframes_alineados.values(), axis=0, ignore_index=True)\n",
    "\n",
    "# Mostrar el shape del DataFrame combinado\n",
    "print(f\"Shape del DataFrame '{nombre_merged}': {globals()[nombre_merged].shape}\")\n",
    "\n",
    "# Verificar las primeras filas\n",
    "print(f\"Primeras 5 filas del DataFrame '{nombre_merged}':\")\n",
    "print(globals()[nombre_merged].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5952f74-cd8f-40cf-98fc-4bc809e40306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['col_1', 'col_2', 'col_3', 'col_4', 'col_5', 'col_6', 'col_7', 'col_8',\n",
       "       'col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_14', 'col_15',\n",
       "       'col_16', 'col_17', 'col_18', 'col_19', 'col_20', 'col_21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge2019.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3b1dd52a-c6b5-49ac-9229-bb9421ddc1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    col_2 col_3       col_9  col_10  col_11 col_12      col_13  \\\n",
      "0  EPS025    TI  10/07/2001      85       1    N01  30/09/2019   \n",
      "1  EPS025    TI  30/05/2000      85     125    N01  30/09/2019   \n",
      "2  EPS025    TI  26/11/2000      85       1    N01  30/09/2019   \n",
      "3  EPS025    TI  03/01/1990      85       1    N01  30/09/2019   \n",
      "4  EPS025    TI  07/06/2000      85     430    N01  30/09/2019   \n",
      "\n",
      "                                              col_21  \n",
      "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n"
     ]
    }
   ],
   "source": [
    "# Selecciona las columnas que deseas mantener\n",
    "merge2019 = merge2019[['col_2', 'col_3','col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_21']]\n",
    "#union_2019 = union_2019[['col_2', 'col_3','col_8','col_9', 'col_10', 'col_11', 'col_12', 'col_13', 'col_21']]\n",
    "# Verifica el resultado\n",
    "print(merge2019.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b40c1-e761-4f60-83f1-e755d8f825c7",
   "metadata": {},
   "source": [
    "RENOMBRANDO COLUMNAS POR ULTIMA VEZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ddbfc2c-f526-4d60-b771-0d686f55bb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   colum1 colum2       colum3      colum4       colum5    colum6    colum7  \\\n",
      "0  EPS025     TI   1006413607   RODRIGUEZ    CASTAÑEDA      NANI   MAYERLI   \n",
      "1  EPS025     TI   1006559623  CHAMARRAVI  GUACARAPARE   KINNEDY  BERNARDO   \n",
      "2  EPS025     TI   1010107558       RIVAS      ALVAREZ       YAN    CARLOS   \n",
      "3  EPS025     TI  90010379279     MARQUEZ    HERNANDEZ  PATRICIA       NaN   \n",
      "4  EPS025     TI   1006450537       JAZPE      BARRETO     JULIO    DANIEL   \n",
      "\n",
      "       colum8  colum9  colum10 colum11     colum12  \\\n",
      "0  10/07/2001      85        1     N01  30/09/2019   \n",
      "1  30/05/2000      85      125     N01  30/09/2019   \n",
      "2  26/11/2000      85        1     N01  30/09/2019   \n",
      "3  03/01/1990      85        1     N01  30/09/2019   \n",
      "4  07/06/2000      85      430     N01  30/09/2019   \n",
      "\n",
      "                                             colum13  \n",
      "0  GN0014(CC|1006413607|RODRIGUEZ|CASTAÑEDA|NANI|...  \n",
      "1  GN0169(||||FECHA NACIMIENTO|20/05/2000|30/05/2...  \n",
      "2  GN0031(CC|1010107558|RIVAS|ALVAREZ|YAN|CARLOS|...  \n",
      "3              GN0018(CC|1118542994|CANCELADO RNEC);  \n",
      "4  GN0169(||||FECHA NACIMIENTO|01/07/2000|07/06/2...  \n"
     ]
    }
   ],
   "source": [
    "# Obtiene la cantidad de columnas en el DataFrame\n",
    "num_columns = union_2019.shape[1]\n",
    "\n",
    "# Genera nuevos nombres de columnas: 'colum1', 'colum2', ..., 'columnN'\n",
    "new_columns = [f'colum{i+1}' for i in range(num_columns)]\n",
    "\n",
    "# Asigna los nuevos nombres de columnas al DataFrame\n",
    "union_2019.columns = new_columns\n",
    "\n",
    "# Verifica el resultado\n",
    "print(union_2019.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "94ad6470-ddf6-4886-bae2-8418b42e837a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "colum1     object\n",
       "colum2     object\n",
       "colum3     object\n",
       "colum4     object\n",
       "colum5     object\n",
       "colum6     object\n",
       "colum7     object\n",
       "colum8     object\n",
       "colum9      int64\n",
       "colum10     int64\n",
       "colum11    object\n",
       "colum12    object\n",
       "colum13    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "union_2019.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "40f20b50-cb2a-44fb-a1b7-a8f98a2bc01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo se ha guardado correctamente en: C:\\Users\\carlo\\Downloads\\merged_2018.xlsx\n"
     ]
    }
   ],
   "source": [
    "# Definir la ruta donde se guardará el archivo Excel\n",
    "output_path = r\"C:\\Users\\carlo\\Downloads\\merged_2018.xlsx\"\n",
    "\n",
    "# Guardar el DataFrame como un archivo Excel\n",
    "merged_2018.to_excel(output_path, index=False)\n",
    "\n",
    "print(f\"El archivo se ha guardado correctamente en: {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bc57671-55ad-4524-938f-c1380c280c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col_1</th>\n",
       "      <th>col_2</th>\n",
       "      <th>col_3</th>\n",
       "      <th>col_4</th>\n",
       "      <th>col_5</th>\n",
       "      <th>col_6</th>\n",
       "      <th>col_7</th>\n",
       "      <th>col_8</th>\n",
       "      <th>col_9</th>\n",
       "      <th>col_10</th>\n",
       "      <th>...</th>\n",
       "      <th>col_12</th>\n",
       "      <th>col_13</th>\n",
       "      <th>col_14</th>\n",
       "      <th>col_15</th>\n",
       "      <th>col_16</th>\n",
       "      <th>col_17</th>\n",
       "      <th>col_18</th>\n",
       "      <th>col_19</th>\n",
       "      <th>col_20</th>\n",
       "      <th>col_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EPS025</td>\n",
       "      <td>CE</td>\n",
       "      <td>577635</td>\n",
       "      <td>GUARUYA</td>\n",
       "      <td>YAPUARE</td>\n",
       "      <td>REIMAR</td>\n",
       "      <td>YOLETXI</td>\n",
       "      <td>27/03/1995</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>N01</td>\n",
       "      <td>17/01/2020</td>\n",
       "      <td>CC</td>\n",
       "      <td>1118577595</td>\n",
       "      <td>27/03/1995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GN0059;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1117323965</td>\n",
       "      <td>CABARTE</td>\n",
       "      <td>RAMIREZ</td>\n",
       "      <td>HIVI</td>\n",
       "      <td>YARJAHIDY</td>\n",
       "      <td>14/05/2009</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>N01</td>\n",
       "      <td>20/02/2019</td>\n",
       "      <td>TI</td>\n",
       "      <td>1117326241</td>\n",
       "      <td>14/05/2009</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GN0059;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>EPS025</td>\n",
       "      <td>TI</td>\n",
       "      <td>1007441444</td>\n",
       "      <td>PEREZ</td>\n",
       "      <td>TORRES</td>\n",
       "      <td>DANIA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16/04/2001</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>N01</td>\n",
       "      <td>07/06/2019</td>\n",
       "      <td>TI</td>\n",
       "      <td>1194430280</td>\n",
       "      <td>16/04/2001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GN0059;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   col_1   col_2 col_3       col_4    col_5    col_6   col_7      col_8  \\\n",
       "0      1  EPS025    CE      577635  GUARUYA  YAPUARE  REIMAR    YOLETXI   \n",
       "1      2  EPS025    TI  1117323965  CABARTE  RAMIREZ    HIVI  YARJAHIDY   \n",
       "2      3  EPS025    TI  1007441444    PEREZ   TORRES   DANIA        NaN   \n",
       "\n",
       "        col_9  col_10  ...  col_12      col_13 col_14      col_15      col_16  \\\n",
       "0  27/03/1995      85  ...     N01  17/01/2020     CC  1118577595  27/03/1995   \n",
       "1  14/05/2009      85  ...     N01  20/02/2019     TI  1117326241  14/05/2009   \n",
       "2  16/04/2001      85  ...     N01  07/06/2019     TI  1194430280  16/04/2001   \n",
       "\n",
       "  col_17  col_18  col_19  col_20   col_21  \n",
       "0    1.0     NaN     NaN     NaN  GN0059;  \n",
       "1    1.0     NaN     NaN     NaN  GN0059;  \n",
       "2    1.0     NaN     NaN     NaN  GN0059;  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Si df_1 está en el diccionario 'dataframes', lo puedes acceder así:\n",
    "dataframes['df_1'].head(3)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
